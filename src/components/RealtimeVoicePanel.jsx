'use client'

import { useState, useRef, useEffect, useCallback } from 'react'
import gptConfig from '@/config/gpt-config.json'
import voicePresets from '@/config/voice-presets.json'

export default function RealtimeVoicePanel() {
  // Ana durum y√∂netimi
  const [isConnected, setIsConnected] = useState(false)
  const [isRecording, setIsRecording] = useState(false)
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [isProcessing, setIsProcessing] = useState(false)
  const [currentPreset, setCurrentPreset] = useState('default')
  const [conversationHistory, setConversationHistory] = useState([])
  const [debugInfo, setDebugInfo] = useState([])
  const [lastUserSpeechTime, setLastUserSpeechTime] = useState(0)
  const [currentConversationId, setCurrentConversationId] = useState(null)
  const [userInfo, setUserInfo] = useState(null)

  // WebRTC referanslarƒ±
  const peerConnectionRef = useRef(null)
  const localStreamRef = useRef(null)
  const remoteStreamRef = useRef(null)
  const dataChannelRef = useRef(null)
  const audioContextRef = useRef(null)
  const audioQueueRef = useRef([])
  const isPlayingRef = useRef(false)
  const operationTimers = useRef({}) // ƒ∞≈ülem s√ºrelerini takip etmek i√ßin

  // Geli≈ümi≈ü debug sistemi - i≈ülem s√ºrelerini detaylƒ± takip eder
  const addDebugInfo = useCallback((message, type = 'info', operation = null, duration = null) => {
    const now = new Date()
    const timestamp = now.toLocaleTimeString('tr-TR')
    const milliseconds = now.getMilliseconds().toString().padStart(3, '0')
    const fullTimestamp = `${timestamp}.${milliseconds}`
    
    // ƒ∞≈ülem s√ºresi bilgisi varsa ekle
    const durationText = duration ? ` (${duration}ms)` : ''
    const operationText = operation ? `[${operation}] ` : ''
    
    setDebugInfo(prev => [...prev, { 
      message: `${operationText}${message}${durationText}`, 
      type, 
      timestamp: fullTimestamp,
      operation,
      duration
    }])
    
    // Console'a detaylƒ± debug bilgisi yazdƒ±r
    const consoleMessage = `[${fullTimestamp}] ${operationText}${message}${durationText}`
    
    switch (type) {
      case 'error':
        console.error('üî¥ REALTIME VOICE PANEL ERROR:', consoleMessage)
        break
      case 'warning':
        console.warn('üü° REALTIME VOICE PANEL WARNING:', consoleMessage)
        break
      case 'success':
        console.log('üü¢ REALTIME VOICE PANEL SUCCESS:', consoleMessage)
        break
      case 'info':
      default:
        console.log('üîµ REALTIME VOICE PANEL INFO:', consoleMessage)
        break
    }
  }, [])

  // Conversation history'yi y√ºkle
  const loadConversationHistory = useCallback(async () => {
    try {
      const response = await fetch('/api/conversation')
      if (response.ok) {
        const data = await response.json()
        setConversationHistory(data.conversation?.messages || [])
        setCurrentConversationId(data.conversation?.id || null)
        setUserInfo(data.user)
        addDebugInfo(`Realtime conversation history loaded: ${data.conversation?.messages?.length || 0} messages`, 'info', 'CONVERSATION')
      }
    } catch (error) {
      addDebugInfo(`Failed to load conversation history: ${error.message}`, 'error', 'CONVERSATION')
    }
  }, [addDebugInfo])

  // Yeni mesaj ekle
  const addMessageToHistory = useCallback(async (role, content) => {
    try {
      const response = await fetch('/api/conversation', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          conversationId: currentConversationId,
          role,
          content
        })
      })

      if (response.ok) {
        const data = await response.json()
        setCurrentConversationId(data.conversationId)
        
        // Local state'i g√ºncelle
        setConversationHistory(prev => [
          ...prev,
          { role: role.toUpperCase(), content, timestamp: new Date().toISOString() }
        ])
        
        addDebugInfo(`Realtime message added to history: ${role} - ${content.substring(0, 50)}...`, 'info', 'CONVERSATION')
      }
    } catch (error) {
      addDebugInfo(`Failed to add message to history: ${error.message}`, 'error', 'CONVERSATION')
    }
  }, [currentConversationId, addDebugInfo])

  // ƒ∞≈ülem ba≈ülatma - s√ºre takibi i√ßin
  const startOperation = useCallback((operationName) => {
    operationTimers.current[operationName] = Date.now()
    addDebugInfo(`${operationName} ba≈ülatƒ±ldƒ±`, 'info', operationName)
  }, [addDebugInfo])

  // API √ßaƒürƒ±sƒ± takibi i√ßin √∂zel fonksiyon
  const trackAPICall = useCallback((apiName, endpoint, method = 'POST') => {
    const timestamp = new Date().toLocaleTimeString('tr-TR')
    console.log(`üöÄ REALTIME API CALL START: [${apiName}] ${method} ${endpoint} - ${timestamp}`)
    addDebugInfo(`${apiName} API √ßaƒürƒ±sƒ± ba≈ülatƒ±ldƒ±: ${method} ${endpoint}`, 'info', apiName)
  }, [addDebugInfo])

  // API ba≈üarƒ± takibi
  const trackAPISuccess = useCallback((apiName, responseData = null, duration = null) => {
    const timestamp = new Date().toLocaleTimeString('tr-TR')
    const dataInfo = responseData ? ` - Data: ${JSON.stringify(responseData).substring(0, 100)}...` : ''
    console.log(`‚úÖ REALTIME API SUCCESS: [${apiName}] Tamamlandƒ±${dataInfo} - ${timestamp}`)
    addDebugInfo(`${apiName} API ba≈üarƒ±lƒ±`, 'success', apiName, duration)
  }, [addDebugInfo])

  // API hata takibi
  const trackAPIError = useCallback((apiName, error, duration = null) => {
    const timestamp = new Date().toLocaleTimeString('tr-TR')
    console.error(`‚ùå REALTIME API ERROR: [${apiName}] ${error.message || error} - ${timestamp}`)
    addDebugInfo(`${apiName} API hatasƒ±: ${error.message || error}`, 'error', apiName, duration)
  }, [addDebugInfo])

  // ƒ∞≈ülem bitirme - s√ºre hesaplama ile
  const endOperation = useCallback((operationName, success = true) => {
    const startTime = operationTimers.current[operationName]
    if (startTime) {
      const duration = Date.now() - startTime
      const type = success ? 'success' : 'error'
      addDebugInfo(`${operationName} tamamlandƒ±`, type, operationName, duration)
      delete operationTimers.current[operationName]
      return duration
    }
    return 0
  }, [addDebugInfo])

  // Basit baƒülantƒ± ba≈ülatma (WebRTC olmadan)
  const initializeConnection = useCallback(async () => {
    try {
      startOperation('CONNECTION')
      addDebugInfo('Baƒülantƒ± ba≈ülatƒ±lƒ±yor...', 'info', 'CONNECTION')

      // Mikrofon eri≈üimini test et
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      })

      // Test i√ßin hemen kapat
      stream.getTracks().forEach(track => track.stop())
      
      const duration = endOperation('CONNECTION', true)
      addDebugInfo('Mikrofon eri≈üimi test edildi', 'success', 'CONNECTION', duration)
      setIsConnected(true)
      addDebugInfo('Sistem hazƒ±r', 'success', 'CONNECTION')

    } catch (error) {
      endOperation('CONNECTION', false)
      addDebugInfo(`Baƒülantƒ± hatasƒ±: ${error.message}`, 'error', 'CONNECTION')
    }
  }, [startOperation, endOperation, addDebugInfo])

  // Uzak komutlarƒ± i≈üleme
  const handleRemoteCommand = useCallback((command) => {
    addDebugInfo(`Uzak komut alƒ±ndƒ±: ${command.type}`, 'info', 'REMOTE_COMMAND')
    
    switch (command.type) {
      case 'start_speaking':
        setIsSpeaking(true)
        break
      case 'stop_speaking':
        setIsSpeaking(false)
        break
      case 'change_preset':
        setCurrentPreset(command.preset)
        break
      case 'system_message':
        addDebugInfo(`Sistem mesajƒ±: ${command.message}`, 'info', 'REMOTE_COMMAND')
        break
      default:
        addDebugInfo(`Bilinmeyen komut: ${command.type}`, 'warning', 'REMOTE_COMMAND')
    }
  }, [addDebugInfo])

  // Realtime ses i≈üleme
  const processRealtimeAudio = useCallback(async (audioBlob) => {
    try {
      startOperation('STT')
      addDebugInfo(`Realtime ses i≈üleme ba≈ülatƒ±ldƒ±: ${audioBlob.size} bytes`, 'info', 'STT')

      // OpenAI Whisper ile i≈üleme
      const formData = new FormData()
      formData.append('audio', audioBlob, 'realtime-audio.webm')

      const response = await fetch('/api/stt/stream', {
        method: 'POST',
        body: formData
      })

      if (response.ok) {
        const result = await response.json()
        
        if (result.text && result.text.trim()) {
          const currentTime = Date.now()
          const timeSinceLastUserSpeech = currentTime - lastUserSpeechTime
          
          // AI konu≈üurken gelen sesi engelle
          if (isSpeaking && timeSinceLastUserSpeech < 5000) {
            addDebugInfo('AI konu≈üurken gelen ses, yok sayƒ±lƒ±yor', 'warning', 'STT')
            endOperation('STT', false)
            return
          }
          
          // Konu≈üma ge√ßmi≈üine ekleme
          setConversationHistory(prev => [...prev, {
            type: 'user',
            text: result.text,
            timestamp: new Date().toISOString()
          }])
          
          setLastUserSpeechTime(currentTime)

          // GPT ile i≈üleme
          await processRealtimeChat(result.text)
        }
      } else {
        const errorText = await response.text()
        addDebugInfo(`STT hatasƒ±: ${errorText}`, 'error', 'STT')
      }

      const duration = endOperation('STT', true)
      addDebugInfo(`STT ba≈üarƒ±lƒ±: "${result.text}"`, 'success', 'STT', duration)

    } catch (error) {
      endOperation('STT', false)
      addDebugInfo(`Realtime ses i≈üleme hatasƒ±: ${error.message}`, 'error', 'STT')
    }
  }, [isSpeaking, lastUserSpeechTime, startOperation, endOperation, addDebugInfo])

  // Realtime chat i≈üleme
  const processRealtimeChat = useCallback(async (userMessage) => {
    try {
      // Input validation
      if (!userMessage.trim()) {
        addDebugInfo('Bo≈ü input, yanƒ±t verilmiyor', 'warning', 'GPT')
        return
      }

      const trimmedMessage = userMessage.trim()
      if (trimmedMessage.length < 2) {
        addDebugInfo('√áok kƒ±sa input, yanƒ±t verilmiyor', 'warning', 'GPT')
        return
      }

      // AI'nin kendi yanƒ±tlarƒ±nƒ± engelle
      const aiResponsePatterns = [
        'Merhaba, ben Selin', 'Size nasƒ±l yardƒ±mcƒ± olabilirim', 'Nasƒ±lsƒ±nƒ±z',
        'Sa√ß Ekimi Merkezi', 'FUE tekniƒüi', 'FUT tekniƒüi', 'DHI tekniƒüi'
      ]
      
      const isAiResponse = aiResponsePatterns.some(pattern =>
        trimmedMessage.toLowerCase().includes(pattern.toLowerCase())
      )
      
      if (isAiResponse) {
        addDebugInfo('AI kendi yanƒ±tƒ±nƒ± tekrar i≈ülemeye √ßalƒ±≈üƒ±yor, engellendi', 'warning', 'GPT')
        return
      }

      // Kullanƒ±cƒ± mesajƒ±nƒ± ge√ßmi≈üe ekle
      await addMessageToHistory('user', trimmedMessage)

      startOperation('GPT')
      addDebugInfo(`Realtime chat ba≈ülatƒ±ldƒ±: "${trimmedMessage}"`, 'info', 'GPT')

      // ElevenLabs default preset'i al
      const preset = voicePresets.presets['default']
      
      // Ki≈üisel bilgileri system prompt'a ekle
      const personalInfo = userInfo ? `
KULLANICI Bƒ∞LGƒ∞LERƒ∞:
- Ad: ${userInfo.name || 'Bilinmiyor'}
- Email: ${userInfo.email || 'Bilinmiyor'}
- ID: ${userInfo.id || 'Bilinmiyor'}

Bu bilgileri kullanarak ki≈üisel bir baƒü kur ve ge√ßmi≈ü konu≈ümalarƒ± hatƒ±rla.
` : ''

      // GPT config'i preset ile birle≈ütir
      const systemPrompt = `${gptConfig.system_prompt}\n\n${personalInfo}\n\n${preset.style_instructions}\n\n${gptConfig.voice_guidelines.sentence_structure}`
      
      // Conversation history'yi messages array'ine ekle
      const historyMessages = conversationHistory.map(msg => ({
        role: msg.role.toLowerCase(),
        content: msg.content
      }))

      const response = await fetch('/api/chat/stream', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          prompt: trimmedMessage,
          system_prompt: systemPrompt,
          conversation_history: historyMessages,
          max_tokens: gptConfig.technical_instructions.max_tokens,
          temperature: gptConfig.technical_instructions.temperature
        })
      })

      if (response.ok) {
        const reader = response.body.getReader()
        const decoder = new TextDecoder()
        let buffer = ''
        let fullResponse = ''

        while (true) {
          const { done, value } = await reader.read()
          if (done) break

          buffer += decoder.decode(value, { stream: true })
          const lines = buffer.split('\n')
          buffer = lines.pop() || ''

          for (const line of lines) {
            if (!line.startsWith('data: ')) continue
            const payload = line.slice(6).trim()
            if (!payload || payload === '[DONE]') continue

            try {
              const data = JSON.parse(payload)
              const chunk = data.text || ''
              if (chunk) {
                fullResponse += chunk
              }
            } catch (e) {
              // JSON parse hatasƒ±, devam et
            }
          }
        }

        if (fullResponse.trim()) {
          addDebugInfo(`AI yanƒ±tƒ±: "${fullResponse.trim()}"`, 'success', 'GPT')
          
          // Konu≈üma ge√ßmi≈üine ekleme
          setConversationHistory(prev => [...prev, {
            type: 'assistant',
            text: fullResponse.trim(),
            timestamp: new Date().toISOString()
          }])

          // TTS ile seslendirme
          await processRealtimeTTS(fullResponse.trim(), preset)
        }
      }

      const duration = endOperation('GPT', true)
      addDebugInfo(`GPT ba≈üarƒ±lƒ± - ${fullResponse.length} karakter`, 'success', 'GPT', duration)
      
      // GPT yanƒ±tƒ±nƒ± ge√ßmi≈üe ekle
      await addMessageToHistory('assistant', fullResponse)

    } catch (error) {
      endOperation('GPT', false)
      addDebugInfo(`Realtime chat hatasƒ±: ${error.message}`, 'error', 'GPT')
    }
  }, [startOperation, endOperation, addDebugInfo, addMessageToHistory, conversationHistory, userInfo])

  // Realtime TTS i≈üleme
  const processRealtimeTTS = useCallback(async (text, preset) => {
    try {
      // TTS ba≈ülamadan √∂nce mikrofonu tamamen durdur
      if (isRecording) {
        if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
          mediaRecorderRef.current.stop()
          mediaRecorderRef.current = null
        }
        
        if (localStreamRef.current) {
          localStreamRef.current.getTracks().forEach(track => track.stop())
          localStreamRef.current = null
        }
        
        setIsRecording(false)
        addDebugInfo('TTS ba≈ülƒ±yor, mikrofon durduruldu', 'info', 'TTS')
      }

      // Kullanƒ±cƒ± metnini koruma altƒ±na al
      const originalUserText = userText
      setUserText('AI konu≈üuyor... (Mikrofon devre dƒ±≈üƒ±)')

      startOperation('TTS')
      addDebugInfo(`Realtime ElevenLabs TTS ba≈ülatƒ±ldƒ±: "${text}"`, 'info', 'TTS')

      const response = await fetch('/api/tts/stream', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          text: text,
          voice_settings: preset.voice_settings
        })
      })

      if (response.ok) {
        const audioBuffer = await response.arrayBuffer()
        const audioBlob = new Blob([audioBuffer], { type: 'audio/mpeg' })
        
        // Ses kuyruƒüuna ekleme
        audioQueueRef.current.push(audioBlob)
        
        // Eƒüer √ßalmƒ±yorsa ba≈ülat
        if (!isPlayingRef.current) {
          playNextAudio()
        }

        const duration = endOperation('TTS', true)
        addDebugInfo(`TTS ba≈üarƒ±lƒ±: ${audioBlob.size} bytes`, 'success', 'TTS', duration)
        
        // Kullanƒ±cƒ± metnini geri y√ºkle
        setUserText(originalUserText)
      }

    } catch (error) {
      endOperation('TTS', false)
      addDebugInfo(`Realtime TTS hatasƒ±: ${error.message}`, 'error', 'TTS')
      
      // Hata durumunda da kullanƒ±cƒ± metnini geri y√ºkle
      setUserText(originalUserText)
    }
  }, [startOperation, endOperation, addDebugInfo, userText])

  // Ses √ßalma kuyruƒüu - p√ºr√ºzs√ºz ge√ßi≈ülerle
  const playNextAudio = useCallback(() => {
    if (audioQueueRef.current.length > 0 && !isPlayingRef.current) {
      isPlayingRef.current = true
      setIsSpeaking(true)
      
      // AI konu≈üurken mikrofonu TAMAMEN durdur
      if (isRecording) {
        if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
          mediaRecorderRef.current.stop()
          mediaRecorderRef.current = null
        }
        
        if (localStreamRef.current) {
          localStreamRef.current.getTracks().forEach(track => track.stop())
          localStreamRef.current = null
        }
        
        setIsRecording(false)
        addDebugInfo('AI konu≈üuyor, mikrofon durduruldu', 'info', 'AUDIO_PLAY')
      }
      
      // TTS √ßalarken mikrofonu Fƒ∞Zƒ∞KSEL olarak kapat (ekstra g√ºvenlik)
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
        mediaRecorderRef.current.stop()
        mediaRecorderRef.current = null
        addDebugInfo('TTS √ßalarken MediaRecorder kapatƒ±ldƒ±', 'info')
      }
      
      if (localStreamRef.current) {
        localStreamRef.current.getTracks().forEach(track => track.stop())
        localStreamRef.current = null
        addDebugInfo('TTS √ßalarken local stream kapatƒ±ldƒ±', 'info')
      }

      const audioBlob = audioQueueRef.current.shift()
      const audioUrl = URL.createObjectURL(audioBlob)
      const audio = new Audio(audioUrl)

      // Ses kalitesi optimizasyonlarƒ±
      audio.volume = 0.9 // Optimum ses seviyesi
      audio.preload = 'auto' // √ñnceden y√ºkleme

      audio.onended = () => {
        URL.revokeObjectURL(audioUrl)
        isPlayingRef.current = false
        setIsSpeaking(false)
        // P√ºr√ºzs√ºz ge√ßi≈ü i√ßin √ßok kƒ±sa bekleme (10ms)
        setTimeout(() => {
          playNextAudio()
        }, 10)
      }

      audio.onerror = () => {
        URL.revokeObjectURL(audioUrl)
        isPlayingRef.current = false
        setIsSpeaking(false)
        playNextAudio()
      }

      audio.play().catch(console.error)
    }
  }, [isRecording, addDebugInfo])

  // Kayƒ±t ba≈ülatma/durdurma
  const toggleRecording = useCallback(async () => {
    const timestamp = new Date().toLocaleTimeString('tr-TR')
    
    if (isRecording) {
      // Kayƒ±t durdur
      console.log(`üëÜ REALTIME USER ACTION: Kayƒ±t durduruluyor - ${timestamp}`)
      
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
        mediaRecorderRef.current.stop()
        mediaRecorderRef.current = null
      }
      
      if (localStreamRef.current) {
        localStreamRef.current.getTracks().forEach(track => track.stop())
        localStreamRef.current = null
      }
      
      setIsRecording(false)
      addDebugInfo('Kayƒ±t durduruldu', 'info', 'RECORDING')
    } else {
      console.log(`üëÜ REALTIME USER ACTION: Kayƒ±t ba≈ülatƒ±lmaya √ßalƒ±≈üƒ±lƒ±yor - ${timestamp}`)
      // AI konu≈üuyorsa kayƒ±t yapma
      if (isSpeaking) {
        console.warn('‚ö†Ô∏è REALTIME USER ACTION BLOCKED: AI konu≈üuyor, kayƒ±t yapƒ±lamƒ±yor')
        addDebugInfo('AI konu≈üuyor, kayƒ±t yapƒ±lamƒ±yor', 'warning', 'RECORDING')
        return
      }
      
      // TTS √ßalƒ±yorsa kayƒ±t ba≈ülatma
      if (isPlayingRef.current) {
        console.warn('‚ö†Ô∏è REALTIME USER ACTION BLOCKED: TTS √ßalƒ±yor, kayƒ±t yapƒ±lamƒ±yor')
        addDebugInfo('TTS √ßalƒ±yor, kayƒ±t yapƒ±lamƒ±yor', 'warning', 'RECORDING')
        return
      }
      
      // Kayƒ±t ba≈ülat
      try {
        console.log('‚úÖ REALTIME USER ACTION SUCCESS: Kayƒ±t ba≈ülatƒ±lƒ±yor')
        startOperation('RECORDING')
        addDebugInfo('Kayƒ±t ba≈ülatƒ±lƒ±yor...', 'info', 'RECORDING')
        
        // Mikrofon eri≈üimi
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            sampleRate: 16000,
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          }
        })

        localStreamRef.current = stream
        addDebugInfo('Mikrofon eri≈üimi ba≈üarƒ±lƒ±', 'success', 'RECORDING')

        // MediaRecorder olu≈ütur
        const mediaRecorder = new MediaRecorder(stream, {
          mimeType: 'audio/webm'
        })
        
        addDebugInfo(`MediaRecorder formatƒ±: audio/webm`, 'info', 'RECORDING')

        mediaRecorderRef.current = mediaRecorder
        setIsRecording(true)
        addDebugInfo('Kayƒ±t ba≈ülatƒ±ldƒ±', 'success', 'RECORDING')

        // Ses verisi geldiƒüinde i≈üle
        mediaRecorder.ondataavailable = async (event) => {
          if (event.data.size > 0) {
            addDebugInfo(`Ses verisi alƒ±ndƒ±: ${event.data.size} bytes`, 'info', 'RECORDING')
            await processRealtimeAudio(event.data)
          }
        }

        // Kayƒ±t hatalarƒ±nƒ± yakala
        mediaRecorder.onerror = (event) => {
          addDebugInfo(`Kayƒ±t hatasƒ±: ${event.error}`, 'error', 'RECORDING')
          setIsRecording(false)
        }

        // Kayƒ±t ba≈ülat (1 saniyede bir chunk)
        mediaRecorder.start(1000)

        const duration = endOperation('RECORDING', true)
        addDebugInfo(`Kayƒ±t ba≈üarƒ±lƒ±`, 'success', 'RECORDING', duration)

      } catch (error) {
        endOperation('RECORDING', false)
        addDebugInfo(`Kayƒ±t ba≈ülatma hatasƒ±: ${error.message}`, 'error', 'RECORDING')
        console.error('Recording error:', error)
      }
    }
  }, [isRecording, isSpeaking, startOperation, endOperation, addDebugInfo, processRealtimeAudio])

  // Baƒülantƒ±yƒ± kapatma
  const disconnect = useCallback(() => {
    if (localStreamRef.current) {
      localStreamRef.current.getTracks().forEach(track => track.stop())
      localStreamRef.current = null
    }

    if (mediaRecorderRef.current) {
      mediaRecorderRef.current.stop()
      mediaRecorderRef.current = null
    }

    setIsConnected(false)
    setIsRecording(false)
    setIsSpeaking(false)
    addDebugInfo('Baƒülantƒ± kapatƒ±ldƒ±', 'info', 'CONNECTION')
  }, [addDebugInfo])

  // Component mount olduƒüunda baƒülantƒ±yƒ± ba≈ülat
  useEffect(() => {
    setDebugInfo([])
    addDebugInfo('Realtime Voice Panel ba≈ülatƒ±ldƒ±', 'info', 'SYSTEM')
    loadConversationHistory()
  }, [])
    
    initializeConnection()
    
    return () => {
      disconnect()
    }
  }, [initializeConnection, disconnect, addDebugInfo])

  return (
    <div className="bg-white rounded-2xl shadow-xl p-6 border border-gray-100">
      {/* Ba≈ülƒ±k */}
      <div className="text-center mb-6">
        <h2 className="text-2xl font-bold text-gray-900 mb-2">Realtime AI Asistan</h2>
        <p className="text-gray-600">WebRTC ile ger√ßek zamanlƒ± sesli konu≈üma</p>
        <div className="mt-2 flex justify-center space-x-2 text-xs text-gray-500">
          <span className="bg-blue-100 text-blue-800 px-2 py-1 rounded">WebRTC</span>
          <span className="bg-green-100 text-green-800 px-2 py-1 rounded">Realtime STT</span>
          <span className="bg-purple-100 text-purple-800 px-2 py-1 rounded">Smart TTS</span>
        </div>
      </div>

      {/* Baƒülantƒ± Durumu */}
      <div className="text-center mb-4">
        <div className={`inline-flex items-center px-3 py-1 rounded-full text-sm font-medium ${
          isConnected ? 'bg-green-100 text-green-800' : 'bg-red-100 text-red-800'
        }`}>
          <div className={`w-2 h-2 rounded-full mr-2 ${
            isConnected ? 'bg-green-500' : 'bg-red-500'
          }`}></div>
          {isConnected ? 'Baƒülƒ±' : 'Baƒülantƒ± Yok'}
        </div>
      </div>

      {/* ElevenLabs Voice Info */}
      <div className="mb-6">
        <h3 className="text-sm font-semibold text-gray-700 mb-3">ElevenLabs Ses Sistemi</h3>
        <div className="bg-gradient-to-r from-purple-50 to-blue-50 rounded-lg p-4 border border-purple-200">
          <div className="text-center">
            <div className="text-2xl mb-2">üéôÔ∏è</div>
            <div className="font-medium text-gray-800">{voicePresets.presets.default.name}</div>
            <div className="text-sm text-gray-600 mt-1">{voicePresets.presets.default.description}</div>
            <div className="text-xs text-gray-500 mt-2">
              Voice ID: <span className="font-mono bg-gray-100 px-2 py-1 rounded">{voicePresets.elevenlabs_config.voice_id}</span>
            </div>
          </div>
        </div>
      </div>

      {/* Kontrol Butonlarƒ± */}
      <div className="text-center mb-6">
        <button
          onClick={toggleRecording}
          disabled={!isConnected || isProcessing || isSpeaking || isPlayingRef.current}
          className={`w-24 h-24 rounded-full text-white font-bold text-lg transition-all duration-200 transform hover:scale-105 disabled:opacity-50 disabled:cursor-not-allowed ${
            isRecording 
              ? 'bg-red-500 hover:bg-red-600 shadow-lg' 
              : isSpeaking
              ? 'bg-yellow-500 shadow-lg'
              : 'bg-gradient-to-r from-indigo-500 to-purple-500 hover:from-indigo-600 hover:to-purple-600 shadow-lg'
          }`}
        >
          {isRecording ? '‚ñ†' : isSpeaking ? 'üîä' : '‚óè'}
        </button>
        <p className="mt-2 text-sm text-gray-600">
          {isRecording ? 'Kayƒ±t yapƒ±lƒ±yor...' : 'Kayƒ±t ba≈ülat'}
        </p>
      </div>

      {/* Durum G√∂stergeleri */}
      <div className="grid grid-cols-3 gap-4 mb-6">
        <div className="text-center p-3 bg-gray-50 rounded-lg">
          <div className={`w-4 h-4 rounded-full mx-auto mb-2 ${
            isRecording ? 'bg-red-500 animate-pulse' : 'bg-gray-300'
          }`}></div>
          <div className="text-xs text-gray-600">Kayƒ±t</div>
        </div>
        <div className="text-center p-3 bg-gray-50 rounded-lg">
          <div className={`w-4 h-4 rounded-full mx-auto mb-2 ${
            isProcessing ? 'bg-yellow-500 animate-pulse' : 'bg-gray-300'
          }`}></div>
          <div className="text-xs text-gray-600">ƒ∞≈üleme</div>
        </div>
        <div className="text-center p-3 bg-gray-50 rounded-lg">
          <div className={`w-4 h-4 rounded-full mx-auto mb-2 ${
            isSpeaking ? 'bg-green-500 animate-pulse' : 'bg-gray-300'
          }`}></div>
          <div className="text-xs text-gray-600">Konu≈üma</div>
        </div>
      </div>

      {/* Konu≈üma Ge√ßmi≈üi */}
      <div className="mb-6">
        <h3 className="text-sm font-semibold text-gray-700 mb-3">Konu≈üma Ge√ßmi≈üi</h3>
        <div className="bg-gray-50 rounded-lg p-4 max-h-40 overflow-y-auto">
          {conversationHistory.length === 0 ? (
            <div className="text-gray-500 text-sm">Hen√ºz konu≈üma yok...</div>
          ) : (
            conversationHistory.map((message, index) => (
              <div key={index} className={`mb-2 p-2 rounded ${
                message.type === 'user' 
                  ? 'bg-blue-100 text-blue-800 ml-4' 
                  : 'bg-green-100 text-green-800 mr-4'
              }`}>
                <div className="text-xs text-gray-500 mb-1">
                  {message.type === 'user' ? 'Sen' : 'AI'} - {new Date(message.timestamp).toLocaleTimeString()}
                </div>
                <div className="text-sm">{message.text}</div>
              </div>
            ))
          )}
        </div>
      </div>

      {/* Debug Bilgileri - Kompakt ƒ∞≈ülem Takibi */}
      <div className="mb-6">
        <div className="flex justify-between items-center mb-2">
          <h3 className="text-sm font-semibold text-gray-700">Debug Bilgileri - ƒ∞≈ülem Takibi</h3>
          <button
            onClick={() => setDebugInfo([])}
            className="text-xs text-gray-500 hover:text-gray-700 px-2 py-1 rounded hover:bg-gray-100"
          >
            Temizle
          </button>
        </div>
        <div className="bg-gray-900 text-green-400 p-3 rounded-lg text-xs font-mono max-h-32 overflow-y-auto">
          {debugInfo.length === 0 ? (
            <div className="text-gray-500">Debug bilgileri burada g√∂r√ºnecek...</div>
          ) : (
            debugInfo.map((info, index) => (
              <div key={index} className={`mb-1 py-1 px-2 rounded ${
                info.type === 'error' ? 'text-red-400 bg-red-900/20' :
                info.type === 'success' ? 'text-green-400 bg-green-900/20' :
                info.type === 'warning' ? 'text-yellow-400 bg-yellow-900/20' :
                'text-blue-400 bg-blue-900/20'
              }`}>
                <div className="flex items-center justify-between">
                  <div className="flex items-center space-x-2">
                    <span className="text-gray-500 text-xs">[{info.timestamp}]</span>
                    <span className={`px-2 py-0.5 rounded text-xs font-medium ${
                      info.type === 'error' ? 'bg-red-500/20 text-red-300' :
                      info.type === 'success' ? 'bg-green-500/20 text-green-300' :
                      info.type === 'warning' ? 'bg-yellow-500/20 text-yellow-300' :
                      'bg-blue-500/20 text-blue-300'
                    }`}>
                      {info.operation || 'INFO'}
                    </span>
                    <span className="font-medium">{info.message}</span>
                  </div>
                  {info.duration && (
                    <span className="text-gray-300 text-xs font-mono bg-black/30 px-2 py-0.5 rounded">
                      {info.duration}ms
                    </span>
                  )}
                </div>
              </div>
            ))
          )}
        </div>
      </div>

      {/* Baƒülantƒ± Kontrol√º */}
      <div className="text-center">
        <button
          onClick={isConnected ? disconnect : initializeConnection}
          className={`px-4 py-2 rounded-lg text-sm font-medium transition-colors ${
            isConnected 
              ? 'bg-red-100 text-red-800 hover:bg-red-200' 
              : 'bg-green-100 text-green-800 hover:bg-green-200'
          }`}
        >
          {isConnected ? 'Baƒülantƒ±yƒ± Kes' : 'Baƒülan'}
        </button>
      </div>
    </div>
  )
}