'use client'

import { useState, useRef, useEffect, useCallback } from 'react'
import gptConfig from '@/config/gpt-config.json'
import voicePresets from '@/config/voice-presets.json'

export default function RealtimeVoicePanel() {
  // Ana durum yÃ¶netimi
  const [isConnected, setIsConnected] = useState(false)
  const [isRecording, setIsRecording] = useState(false)
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [isProcessing, setIsProcessing] = useState(false)
  const [currentPreset, setCurrentPreset] = useState('default')
  const [conversationHistory, setConversationHistory] = useState([])
  const [debugInfo, setDebugInfo] = useState([])
  const [lastUserSpeechTime, setLastUserSpeechTime] = useState(0)
  const [currentConversationId, setCurrentConversationId] = useState(null)
  const [userInfo, setUserInfo] = useState(null)

  // WebRTC referanslarÄ±
  const peerConnectionRef = useRef(null)
  const localStreamRef = useRef(null)
  const remoteStreamRef = useRef(null)
  const dataChannelRef = useRef(null)
  const audioContextRef = useRef(null)
  const audioQueueRef = useRef([])
  const isPlayingRef = useRef(false)
  const operationTimers = useRef({}) // Ä°ÅŸlem sÃ¼relerini takip etmek iÃ§in

  // GeliÅŸmiÅŸ debug sistemi - iÅŸlem sÃ¼relerini detaylÄ± takip eder
  const addDebugInfo = useCallback((message, type = 'info', operation = null, duration = null) => {
    const now = new Date()
    const timestamp = now.toLocaleTimeString('tr-TR')
    const milliseconds = now.getMilliseconds().toString().padStart(3, '0')
    const fullTimestamp = `${timestamp}.${milliseconds}`
    
    // Ä°ÅŸlem sÃ¼resi bilgisi varsa ekle
    const durationText = duration ? ` (${duration}ms)` : ''
    const operationText = operation ? `[${operation}] ` : ''
    
    setDebugInfo(prev => [...prev, { 
      message: `${operationText}${message}${durationText}`, 
      type, 
      timestamp: fullTimestamp,
      operation,
      duration
    }])
    
    // Console'a detaylÄ± debug bilgisi yazdÄ±r
    const consoleMessage = `[${fullTimestamp}] ${operationText}${message}${durationText}`
    
    switch (type) {
      case 'error':
        console.error('ğŸ”´ REALTIME VOICE PANEL ERROR:', consoleMessage)
        break
      case 'warning':
        console.warn('ğŸŸ¡ REALTIME VOICE PANEL WARNING:', consoleMessage)
        break
      case 'success':
        console.log('ğŸŸ¢ REALTIME VOICE PANEL SUCCESS:', consoleMessage)
        break
      case 'info':
      default:
        console.log('ğŸ”µ REALTIME VOICE PANEL INFO:', consoleMessage)
        break
    }
  }, [])

  // Conversation history'yi yÃ¼kle
  const loadConversationHistory = useCallback(async () => {
    try {
      const response = await fetch('/api/conversation')
      if (response.ok) {
        const data = await response.json()
        setConversationHistory(data.conversation?.messages || [])
        setCurrentConversationId(data.conversation?.id || null)
        setUserInfo(data.user)
        addDebugInfo(`Realtime conversation history loaded: ${data.conversation?.messages?.length || 0} messages`, 'info', 'CONVERSATION')
      }
    } catch (error) {
      addDebugInfo(`Failed to load conversation history: ${error.message}`, 'error', 'CONVERSATION')
    }
  }, [addDebugInfo])

  // Yeni mesaj ekle
  const addMessageToHistory = useCallback(async (role, content) => {
    try {
      const response = await fetch('/api/conversation', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          conversationId: currentConversationId,
          role,
          content
        })
      })

      if (response.ok) {
        const data = await response.json()
        setCurrentConversationId(data.conversationId)
        
        // Local state'i gÃ¼ncelle
        setConversationHistory(prev => [
          ...prev,
          { role: role.toUpperCase(), content, timestamp: new Date().toISOString() }
        ])
        
        addDebugInfo(`Realtime message added to history: ${role} - ${content.substring(0, 50)}...`, 'info', 'CONVERSATION')
      }
    } catch (error) {
      addDebugInfo(`Failed to add message to history: ${error.message}`, 'error', 'CONVERSATION')
    }
  }, [currentConversationId, addDebugInfo])

  // Ä°ÅŸlem baÅŸlatma - sÃ¼re takibi iÃ§in
  const startOperation = useCallback((operationName) => {
    operationTimers.current[operationName] = Date.now()
    addDebugInfo(`${operationName} baÅŸlatÄ±ldÄ±`, 'info', operationName)
  }, [addDebugInfo])

  // API Ã§aÄŸrÄ±sÄ± takibi iÃ§in Ã¶zel fonksiyon
  const trackAPICall = useCallback((apiName, endpoint, method = 'POST') => {
    const timestamp = new Date().toLocaleTimeString('tr-TR')
    console.log(`ğŸš€ REALTIME API CALL START: [${apiName}] ${method} ${endpoint} - ${timestamp}`)
    addDebugInfo(`${apiName} API Ã§aÄŸrÄ±sÄ± baÅŸlatÄ±ldÄ±: ${method} ${endpoint}`, 'info', apiName)
  }, [addDebugInfo])

  // API baÅŸarÄ± takibi
  const trackAPISuccess = useCallback((apiName, responseData = null, duration = null) => {
    const timestamp = new Date().toLocaleTimeString('tr-TR')
    const dataInfo = responseData ? ` - Data: ${JSON.stringify(responseData).substring(0, 100)}...` : ''
    console.log(`âœ… REALTIME API SUCCESS: [${apiName}] TamamlandÄ±${dataInfo} - ${timestamp}`)
    addDebugInfo(`${apiName} API baÅŸarÄ±lÄ±`, 'success', apiName, duration)
  }, [addDebugInfo])

  // API hata takibi
  const trackAPIError = useCallback((apiName, error, duration = null) => {
    const timestamp = new Date().toLocaleTimeString('tr-TR')
    console.error(`âŒ REALTIME API ERROR: [${apiName}] ${error.message || error} - ${timestamp}`)
    addDebugInfo(`${apiName} API hatasÄ±: ${error.message || error}`, 'error', apiName, duration)
  }, [addDebugInfo])

  // Ä°ÅŸlem bitirme - sÃ¼re hesaplama ile
  const endOperation = useCallback((operationName, success = true) => {
    const startTime = operationTimers.current[operationName]
    if (startTime) {
      const duration = Date.now() - startTime
      const type = success ? 'success' : 'error'
      addDebugInfo(`${operationName} tamamlandÄ±`, type, operationName, duration)
      delete operationTimers.current[operationName]
      return duration
    }
    return 0
  }, [addDebugInfo])

  // Basit baÄŸlantÄ± baÅŸlatma (WebRTC olmadan)
  const initializeConnection = useCallback(async () => {
    try {
      startOperation('CONNECTION')
      addDebugInfo('BaÄŸlantÄ± baÅŸlatÄ±lÄ±yor...', 'info', 'CONNECTION')

      // Mikrofon eriÅŸimini test et
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      })

      // Test iÃ§in hemen kapat
      stream.getTracks().forEach(track => track.stop())
      
      const duration = endOperation('CONNECTION', true)
      addDebugInfo('Mikrofon eriÅŸimi test edildi', 'success', 'CONNECTION', duration)
      setIsConnected(true)
      addDebugInfo('Sistem hazÄ±r', 'success', 'CONNECTION')

    } catch (error) {
      endOperation('CONNECTION', false)
      addDebugInfo(`BaÄŸlantÄ± hatasÄ±: ${error.message}`, 'error', 'CONNECTION')
    }
  }, [startOperation, endOperation, addDebugInfo])

  // Uzak komutlarÄ± iÅŸleme
  const handleRemoteCommand = useCallback((command) => {
    addDebugInfo(`Uzak komut alÄ±ndÄ±: ${command.type}`, 'info', 'REMOTE_COMMAND')
    
    switch (command.type) {
      case 'start_speaking':
        setIsSpeaking(true)
        break
      case 'stop_speaking':
        setIsSpeaking(false)
        break
      case 'change_preset':
        setCurrentPreset(command.preset)
        break
      case 'system_message':
        addDebugInfo(`Sistem mesajÄ±: ${command.message}`, 'info', 'REMOTE_COMMAND')
        break
      default:
        addDebugInfo(`Bilinmeyen komut: ${command.type}`, 'warning', 'REMOTE_COMMAND')
    }
  }, [addDebugInfo])

  // Realtime ses iÅŸleme
  const processRealtimeAudio = useCallback(async (audioBlob) => {
    try {
      startOperation('STT')
      addDebugInfo(`Realtime ses iÅŸleme baÅŸlatÄ±ldÄ±: ${audioBlob.size} bytes`, 'info', 'STT')

      // OpenAI Whisper ile iÅŸleme
      const formData = new FormData()
      formData.append('audio', audioBlob, 'realtime-audio.webm')

      const response = await fetch('/api/stt/stream', {
        method: 'POST',
        body: formData
      })

      if (response.ok) {
        const result = await response.json()
        
        if (result.text && result.text.trim()) {
          const currentTime = Date.now()
          const timeSinceLastUserSpeech = currentTime - lastUserSpeechTime
          
          // AI konuÅŸurken gelen sesi engelle
          if (isSpeaking && timeSinceLastUserSpeech < 5000) {
            addDebugInfo('AI konuÅŸurken gelen ses, yok sayÄ±lÄ±yor', 'warning', 'STT')
            endOperation('STT', false)
            return
          }
          
          // KonuÅŸma geÃ§miÅŸine ekleme
          setConversationHistory(prev => [...prev, {
            type: 'user',
            text: result.text,
            timestamp: new Date().toISOString()
          }])
          
          setLastUserSpeechTime(currentTime)

          // GPT ile iÅŸleme
          await processRealtimeChat(result.text)
        }
      } else {
        const errorText = await response.text()
        addDebugInfo(`STT hatasÄ±: ${errorText}`, 'error', 'STT')
      }

      const duration = endOperation('STT', true)
      addDebugInfo(`STT baÅŸarÄ±lÄ±: "${result.text}"`, 'success', 'STT', duration)

    } catch (error) {
      endOperation('STT', false)
      addDebugInfo(`Realtime ses iÅŸleme hatasÄ±: ${error.message}`, 'error', 'STT')
    }
  }, [isSpeaking, lastUserSpeechTime, startOperation, endOperation, addDebugInfo])

  // Realtime chat iÅŸleme
  const processRealtimeChat = useCallback(async (userMessage) => {
    try {
      // Input validation
      if (!userMessage.trim()) {
        addDebugInfo('BoÅŸ input, yanÄ±t verilmiyor', 'warning', 'GPT')
        return
      }

      const trimmedMessage = userMessage.trim()
      if (trimmedMessage.length < 2) {
        addDebugInfo('Ã‡ok kÄ±sa input, yanÄ±t verilmiyor', 'warning', 'GPT')
        return
      }

      // AI'nin kendi yanÄ±tlarÄ±nÄ± engelle
      const aiResponsePatterns = [
        'Merhaba, ben Selin', 'Size nasÄ±l yardÄ±mcÄ± olabilirim', 'NasÄ±lsÄ±nÄ±z',
        'SaÃ§ Ekimi Merkezi', 'FUE tekniÄŸi', 'FUT tekniÄŸi', 'DHI tekniÄŸi'
      ]
      
      const isAiResponse = aiResponsePatterns.some(pattern =>
        trimmedMessage.toLowerCase().includes(pattern.toLowerCase())
      )
      
      if (isAiResponse) {
        addDebugInfo('AI kendi yanÄ±tÄ±nÄ± tekrar iÅŸlemeye Ã§alÄ±ÅŸÄ±yor, engellendi', 'warning', 'GPT')
        return
      }

      // KullanÄ±cÄ± mesajÄ±nÄ± geÃ§miÅŸe ekle
      await addMessageToHistory('user', trimmedMessage)

      startOperation('GPT')
      addDebugInfo(`Realtime chat baÅŸlatÄ±ldÄ±: "${trimmedMessage}"`, 'info', 'GPT')

      // ElevenLabs default preset'i al
      const preset = voicePresets.presets['default']
      
      // KiÅŸisel bilgileri system prompt'a ekle
      const personalInfo = userInfo ? `
KULLANICI BÄ°LGÄ°LERÄ°:
- Ad: ${userInfo.name || 'Bilinmiyor'}
- Email: ${userInfo.email || 'Bilinmiyor'}
- ID: ${userInfo.id || 'Bilinmiyor'}

Bu bilgileri kullanarak kiÅŸisel bir baÄŸ kur ve geÃ§miÅŸ konuÅŸmalarÄ± hatÄ±rla.
` : ''

      // GPT config'i preset ile birleÅŸtir
      const systemPrompt = `${gptConfig.system_prompt}\n\n${personalInfo}\n\n${preset.style_instructions}\n\n${gptConfig.voice_guidelines.sentence_structure}`
      
      // Conversation history'yi messages array'ine ekle
      const historyMessages = conversationHistory.map(msg => ({
        role: msg.role.toLowerCase(),
        content: msg.content
      }))

      const response = await fetch('/api/chat/stream', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          prompt: trimmedMessage,
          system_prompt: systemPrompt,
          conversation_history: historyMessages,
          max_tokens: gptConfig.technical_instructions.max_tokens,
          temperature: gptConfig.technical_instructions.temperature
        })
      })

      if (response.ok) {
        const reader = response.body.getReader()
        const decoder = new TextDecoder()
        let buffer = ''
        let fullResponse = ''

        while (true) {
          const { done, value } = await reader.read()
          if (done) break

          buffer += decoder.decode(value, { stream: true })
          const lines = buffer.split('\n')
          buffer = lines.pop() || ''

          for (const line of lines) {
            if (!line.startsWith('data: ')) continue
            const payload = line.slice(6).trim()
            if (!payload || payload === '[DONE]') continue

            try {
              const data = JSON.parse(payload)
              const chunk = data.text || ''
              if (chunk) {
                fullResponse += chunk
              }
            } catch (e) {
              // JSON parse hatasÄ±, devam et
            }
          }
        }

        if (fullResponse.trim()) {
          addDebugInfo(`AI yanÄ±tÄ±: "${fullResponse.trim()}"`, 'success', 'GPT')
          
          // KonuÅŸma geÃ§miÅŸine ekleme
          setConversationHistory(prev => [...prev, {
            type: 'assistant',
            text: fullResponse.trim(),
            timestamp: new Date().toISOString()
          }])

          // TTS ile seslendirme
          await processRealtimeTTS(fullResponse.trim(), preset)
        }
      }

      const duration = endOperation('GPT', true)
      addDebugInfo(`GPT baÅŸarÄ±lÄ± - ${fullResponse.length} karakter`, 'success', 'GPT', duration)
      
      // GPT yanÄ±tÄ±nÄ± geÃ§miÅŸe ekle
      await addMessageToHistory('assistant', fullResponse)

    } catch (error) {
      endOperation('GPT', false)
      addDebugInfo(`Realtime chat hatasÄ±: ${error.message}`, 'error', 'GPT')
    }
  }, [startOperation, endOperation, addDebugInfo, addMessageToHistory, conversationHistory, userInfo])

  // Realtime TTS iÅŸleme
  const processRealtimeTTS = useCallback(async (text, preset) => {
    try {
      // TTS baÅŸlamadan Ã¶nce mikrofonu tamamen durdur
      if (isRecording) {
        if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
          mediaRecorderRef.current.stop()
          mediaRecorderRef.current = null
        }
        
        if (localStreamRef.current) {
          localStreamRef.current.getTracks().forEach(track => track.stop())
          localStreamRef.current = null
        }
        
        setIsRecording(false)
        addDebugInfo('TTS baÅŸlÄ±yor, mikrofon durduruldu', 'info', 'TTS')
      }

      // KullanÄ±cÄ± metnini koruma altÄ±na al
      const originalUserText = userText
      setUserText('AI konuÅŸuyor... (Mikrofon devre dÄ±ÅŸÄ±)')

      startOperation('TTS')
      addDebugInfo(`Realtime ElevenLabs TTS baÅŸlatÄ±ldÄ±: "${text}"`, 'info', 'TTS')

      const response = await fetch('/api/tts/stream', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          text: text,
          voice_settings: preset.voice_settings
        })
      })

      if (response.ok) {
        const audioBuffer = await response.arrayBuffer()
        const audioBlob = new Blob([audioBuffer], { type: 'audio/mpeg' })
        
        // Ses kuyruÄŸuna ekleme
        audioQueueRef.current.push(audioBlob)
        
        // EÄŸer Ã§almÄ±yorsa baÅŸlat
        if (!isPlayingRef.current) {
          playNextAudio()
        }

        const duration = endOperation('TTS', true)
        addDebugInfo(`TTS baÅŸarÄ±lÄ±: ${audioBlob.size} bytes`, 'success', 'TTS', duration)
        
        // KullanÄ±cÄ± metnini geri yÃ¼kle
        setUserText(originalUserText)
      }

    } catch (error) {
      endOperation('TTS', false)
      addDebugInfo(`Realtime TTS hatasÄ±: ${error.message}`, 'error', 'TTS')
      
      // Hata durumunda da kullanÄ±cÄ± metnini geri yÃ¼kle
      setUserText(originalUserText)
    }
  }, [startOperation, endOperation, addDebugInfo, userText])

  // Ses Ã§alma kuyruÄŸu - pÃ¼rÃ¼zsÃ¼z geÃ§iÅŸlerle
  const playNextAudio = useCallback(() => {
    if (audioQueueRef.current.length > 0 && !isPlayingRef.current) {
      isPlayingRef.current = true
      setIsSpeaking(true)
      
      // AI konuÅŸurken mikrofonu TAMAMEN durdur
      if (isRecording) {
        if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
          mediaRecorderRef.current.stop()
          mediaRecorderRef.current = null
        }
        
        if (localStreamRef.current) {
          localStreamRef.current.getTracks().forEach(track => track.stop())
          localStreamRef.current = null
        }
        
        setIsRecording(false)
        addDebugInfo('AI konuÅŸuyor, mikrofon durduruldu', 'info', 'AUDIO_PLAY')
      }
      
      // TTS Ã§alarken mikrofonu FÄ°ZÄ°KSEL olarak kapat (ekstra gÃ¼venlik)
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
        mediaRecorderRef.current.stop()
        mediaRecorderRef.current = null
        addDebugInfo('TTS Ã§alarken MediaRecorder kapatÄ±ldÄ±', 'info')
      }
      
      if (localStreamRef.current) {
        localStreamRef.current.getTracks().forEach(track => track.stop())
        localStreamRef.current = null
        addDebugInfo('TTS Ã§alarken local stream kapatÄ±ldÄ±', 'info')
      }

      const audioBlob = audioQueueRef.current.shift()
      const audioUrl = URL.createObjectURL(audioBlob)
      const audio = new Audio(audioUrl)

      // Ses kalitesi optimizasyonlarÄ±
      audio.volume = 0.9 // Optimum ses seviyesi
      audio.preload = 'auto' // Ã–nceden yÃ¼kleme

      audio.onended = () => {
        URL.revokeObjectURL(audioUrl)
        isPlayingRef.current = false
        setIsSpeaking(false)
        // PÃ¼rÃ¼zsÃ¼z geÃ§iÅŸ iÃ§in Ã§ok kÄ±sa bekleme (10ms)
        setTimeout(() => {
          playNextAudio()
        }, 10)
      }

      audio.onerror = () => {
        URL.revokeObjectURL(audioUrl)
        isPlayingRef.current = false
        setIsSpeaking(false)
        playNextAudio()
      }

      audio.play().catch(console.error)
    }
  }, [isRecording, addDebugInfo])

  // KayÄ±t baÅŸlatma/durdurma
  const toggleRecording = useCallback(async () => {
    const timestamp = new Date().toLocaleTimeString('tr-TR')
    
    if (isRecording) {
      // KayÄ±t durdur
      console.log(`ğŸ‘† REALTIME USER ACTION: KayÄ±t durduruluyor - ${timestamp}`)
      
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
        mediaRecorderRef.current.stop()
        mediaRecorderRef.current = null
      }
      
      if (localStreamRef.current) {
        localStreamRef.current.getTracks().forEach(track => track.stop())
        localStreamRef.current = null
      }
      
      setIsRecording(false)
      addDebugInfo('KayÄ±t durduruldu', 'info', 'RECORDING')
    } else {
      console.log(`ğŸ‘† REALTIME USER ACTION: KayÄ±t baÅŸlatÄ±lmaya Ã§alÄ±ÅŸÄ±lÄ±yor - ${timestamp}`)
      // AI konuÅŸuyorsa kayÄ±t yapma
      if (isSpeaking) {
        console.warn('âš ï¸ REALTIME USER ACTION BLOCKED: AI konuÅŸuyor, kayÄ±t yapÄ±lamÄ±yor')
        addDebugInfo('AI konuÅŸuyor, kayÄ±t yapÄ±lamÄ±yor', 'warning', 'RECORDING')
        return
      }
      
      // TTS Ã§alÄ±yorsa kayÄ±t baÅŸlatma
      if (isPlayingRef.current) {
        console.warn('âš ï¸ REALTIME USER ACTION BLOCKED: TTS Ã§alÄ±yor, kayÄ±t yapÄ±lamÄ±yor')
        addDebugInfo('TTS Ã§alÄ±yor, kayÄ±t yapÄ±lamÄ±yor', 'warning', 'RECORDING')
        return
      }
      
      // KayÄ±t baÅŸlat
      try {
        console.log('âœ… REALTIME USER ACTION SUCCESS: KayÄ±t baÅŸlatÄ±lÄ±yor')
        startOperation('RECORDING')
        addDebugInfo('KayÄ±t baÅŸlatÄ±lÄ±yor...', 'info', 'RECORDING')
        
        // Mikrofon eriÅŸimi
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            sampleRate: 16000,
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          }
        })

        localStreamRef.current = stream
        addDebugInfo('Mikrofon eriÅŸimi baÅŸarÄ±lÄ±', 'success', 'RECORDING')

        // MediaRecorder oluÅŸtur
        const mediaRecorder = new MediaRecorder(stream, {
          mimeType: 'audio/webm'
        })
        
        addDebugInfo(`MediaRecorder formatÄ±: audio/webm`, 'info', 'RECORDING')

        mediaRecorderRef.current = mediaRecorder
        setIsRecording(true)
        addDebugInfo('KayÄ±t baÅŸlatÄ±ldÄ±', 'success', 'RECORDING')

        // Ses verisi geldiÄŸinde iÅŸle
        mediaRecorder.ondataavailable = async (event) => {
          if (event.data.size > 0) {
            addDebugInfo(`Ses verisi alÄ±ndÄ±: ${event.data.size} bytes`, 'info', 'RECORDING')
            await processRealtimeAudio(event.data)
          }
        }

        // KayÄ±t hatalarÄ±nÄ± yakala
        mediaRecorder.onerror = (event) => {
          addDebugInfo(`KayÄ±t hatasÄ±: ${event.error}`, 'error', 'RECORDING')
          setIsRecording(false)
        }

        // KayÄ±t baÅŸlat (1 saniyede bir chunk)
        mediaRecorder.start(1000)

        const duration = endOperation('RECORDING', true)
        addDebugInfo(`KayÄ±t baÅŸarÄ±lÄ±`, 'success', 'RECORDING', duration)

      } catch (error) {
        endOperation('RECORDING', false)
        addDebugInfo(`KayÄ±t baÅŸlatma hatasÄ±: ${error.message}`, 'error', 'RECORDING')
        console.error('Recording error:', error)
      }
    }
  }, [isRecording, isSpeaking, startOperation, endOperation, addDebugInfo, processRealtimeAudio])

  // BaÄŸlantÄ±yÄ± kapatma
  const disconnect = useCallback(() => {
    if (localStreamRef.current) {
      localStreamRef.current.getTracks().forEach(track => track.stop())
      localStreamRef.current = null
    }

    if (mediaRecorderRef.current) {
      mediaRecorderRef.current.stop()
      mediaRecorderRef.current = null
    }

    setIsConnected(false)
    setIsRecording(false)
    setIsSpeaking(false)
    addDebugInfo('BaÄŸlantÄ± kapatÄ±ldÄ±', 'info', 'CONNECTION')
  }, [addDebugInfo])

  // Component mount olduÄŸunda baÄŸlantÄ±yÄ± baÅŸlat
  useEffect(() => {
    setDebugInfo([])
    addDebugInfo('Realtime Voice Panel baÅŸlatÄ±ldÄ±', 'info', 'SYSTEM')
    loadConversationHistory()
  }, [])
    
    initializeConnection()
    
    return () => {
      disconnect()
    }
  }, [initializeConnection, disconnect, addDebugInfo])

  return (
    <div className="bg-white rounded-2xl shadow-xl p-6 border border-gray-100">
      {/* BaÅŸlÄ±k */}
      <div className="text-center mb-6">
        <h2 className="text-2xl font-bold text-gray-900 mb-2">Realtime AI Asistan</h2>
        <p className="text-gray-600">WebRTC ile gerÃ§ek zamanlÄ± sesli konuÅŸma</p>
        <div className="mt-2 flex justify-center space-x-2 text-xs text-gray-500">
          <span className="bg-blue-100 text-blue-800 px-2 py-1 rounded">WebRTC</span>
          <span className="bg-green-100 text-green-800 px-2 py-1 rounded">Realtime STT</span>
          <span className="bg-purple-100 text-purple-800 px-2 py-1 rounded">Smart TTS</span>
        </div>
      </div>

      {/* BaÄŸlantÄ± Durumu */}
      <div className="text-center mb-4">
        <div className={`inline-flex items-center px-3 py-1 rounded-full text-sm font-medium ${
          isConnected ? 'bg-green-100 text-green-800' : 'bg-red-100 text-red-800'
        }`}>
          <div className={`w-2 h-2 rounded-full mr-2 ${
            isConnected ? 'bg-green-500' : 'bg-red-500'
          }`}></div>
          {isConnected ? 'BaÄŸlÄ±' : 'BaÄŸlantÄ± Yok'}
        </div>
      </div>

      {/* ElevenLabs Voice Info */}
      <div className="mb-6">
        <h3 className="text-sm font-semibold text-gray-700 mb-3">ElevenLabs Ses Sistemi</h3>
        <div className="bg-gradient-to-r from-purple-50 to-blue-50 rounded-lg p-4 border border-purple-200">
          <div className="text-center">
            <div className="text-2xl mb-2">ğŸ™ï¸</div>
            <div className="font-medium text-gray-800">{voicePresets.presets.default.name}</div>
            <div className="text-sm text-gray-600 mt-1">{voicePresets.presets.default.description}</div>
            <div className="text-xs text-gray-500 mt-2">
              Voice ID: <span className="font-mono bg-gray-100 px-2 py-1 rounded">{voicePresets.elevenlabs_config.voice_id}</span>
            </div>
          </div>
        </div>
      </div>

      {/* Kontrol ButonlarÄ± */}
      <div className="text-center mb-6">
        <button
          onClick={toggleRecording}
          disabled={!isConnected || isProcessing || isSpeaking || isPlayingRef.current}
          className={`w-24 h-24 rounded-full text-white font-bold text-lg transition-all duration-200 transform hover:scale-105 disabled:opacity-50 disabled:cursor-not-allowed ${
            isRecording 
              ? 'bg-red-500 hover:bg-red-600 shadow-lg' 
              : isSpeaking
              ? 'bg-yellow-500 shadow-lg'
              : 'bg-gradient-to-r from-indigo-500 to-purple-500 hover:from-indigo-600 hover:to-purple-600 shadow-lg'
          }`}
        >
          {isRecording ? 'â– ' : isSpeaking ? 'ğŸ”Š' : 'â—'}
        </button>
        <p className="mt-2 text-sm text-gray-600">
          {isRecording ? 'KayÄ±t yapÄ±lÄ±yor...' : 'KayÄ±t baÅŸlat'}
        </p>
      </div>

      {/* Durum GÃ¶stergeleri */}
      <div className="grid grid-cols-3 gap-4 mb-6">
        <div className="text-center p-3 bg-gray-50 rounded-lg">
          <div className={`w-4 h-4 rounded-full mx-auto mb-2 ${
            isRecording ? 'bg-red-500 animate-pulse' : 'bg-gray-300'
          }`}></div>
          <div className="text-xs text-gray-600">KayÄ±t</div>
        </div>
        <div className="text-center p-3 bg-gray-50 rounded-lg">
          <div className={`w-4 h-4 rounded-full mx-auto mb-2 ${
            isProcessing ? 'bg-yellow-500 animate-pulse' : 'bg-gray-300'
          }`}></div>
          <div className="text-xs text-gray-600">Ä°ÅŸleme</div>
        </div>
        <div className="text-center p-3 bg-gray-50 rounded-lg">
          <div className={`w-4 h-4 rounded-full mx-auto mb-2 ${
            isSpeaking ? 'bg-green-500 animate-pulse' : 'bg-gray-300'
          }`}></div>
          <div className="text-xs text-gray-600">KonuÅŸma</div>
        </div>
      </div>

      {/* KonuÅŸma GeÃ§miÅŸi */}
      <div className="mb-6">
        <h3 className="text-sm font-semibold text-gray-700 mb-3">KonuÅŸma GeÃ§miÅŸi</h3>
        <div className="bg-gray-50 rounded-lg p-4 max-h-40 overflow-y-auto">
          {conversationHistory.length === 0 ? (
            <div className="text-gray-500 text-sm">HenÃ¼z konuÅŸma yok...</div>
          ) : (
            conversationHistory.map((message, index) => (
              <div key={index} className={`mb-2 p-2 rounded ${
                message.type === 'user' 
                  ? 'bg-blue-100 text-blue-800 ml-4' 
                  : 'bg-green-100 text-green-800 mr-4'
              }`}>
                <div className="text-xs text-gray-500 mb-1">
                  {message.type === 'user' ? 'Sen' : 'AI'} - {new Date(message.timestamp).toLocaleTimeString()}
                </div>
                <div className="text-sm">{message.text}</div>
              </div>
            ))
          )}
        </div>
      </div>

      {/* Debug Bilgileri - Kompakt Ä°ÅŸlem Takibi */}
      <div className="mb-6">
        <div className="flex justify-between items-center mb-2">
          <h3 className="text-sm font-semibold text-gray-700">Debug Bilgileri - Ä°ÅŸlem Takibi</h3>
          <button
            onClick={() => setDebugInfo([])}
            className="text-xs text-gray-500 hover:text-gray-700 px-2 py-1 rounded hover:bg-gray-100"
          >
            Temizle
          </button>
        </div>
        <div className="bg-gray-900 text-green-400 p-3 rounded-lg text-xs font-mono max-h-32 overflow-y-auto">
          {debugInfo.length === 0 ? (
            <div className="text-gray-500">Debug bilgileri burada gÃ¶rÃ¼necek...</div>
          ) : (
            debugInfo.map((info, index) => (
              <div key={index} className={`mb-1 py-1 px-2 rounded ${
                info.type === 'error' ? 'text-red-400 bg-red-900/20' :
                info.type === 'success' ? 'text-green-400 bg-green-900/20' :
                info.type === 'warning' ? 'text-yellow-400 bg-yellow-900/20' :
                'text-blue-400 bg-blue-900/20'
              }`}>
                <div className="flex items-center justify-between">
                  <div className="flex items-center space-x-2">
                    <span className="text-gray-500 text-xs">[{info.timestamp}]</span>
                    <span className={`px-2 py-0.5 rounded text-xs font-medium ${
                      info.type === 'error' ? 'bg-red-500/20 text-red-300' :
                      info.type === 'success' ? 'bg-green-500/20 text-green-300' :
                      info.type === 'warning' ? 'bg-yellow-500/20 text-yellow-300' :
                      'bg-blue-500/20 text-blue-300'
                    }`}>
                      {info.operation || 'INFO'}
                    </span>
                    <span className="font-medium">{info.message}</span>
                  </div>
                  {info.duration && (
                    <span className="text-gray-300 text-xs font-mono bg-black/30 px-2 py-0.5 rounded">
                      {info.duration}ms
                    </span>
                  )}
                </div>
              </div>
            ))
          )}
        </div>
      </div>

      {/* BaÄŸlantÄ± KontrolÃ¼ */}
      <div className="text-center">
        <button
          onClick={isConnected ? disconnect : initializeConnection}
          className={`px-4 py-2 rounded-lg text-sm font-medium transition-colors ${
            isConnected 
              ? 'bg-red-100 text-red-800 hover:bg-red-200' 
              : 'bg-green-100 text-green-800 hover:bg-green-200'
          }`}
        >
          {isConnected ? 'BaÄŸlantÄ±yÄ± Kes' : 'BaÄŸlan'}
        </button>
      </div>
    </div>
  )
}