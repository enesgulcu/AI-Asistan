'use client'

import { useState, useRef, useEffect, useCallback } from 'react'
import gptConfig from '@/config/gpt-config.json'
import voicePresets from '@/config/voice-presets.json'

export default function RealtimeVoicePanel() {
  // Ana durum yÃ¶netimi
  const [isConnected, setIsConnected] = useState(false)
  const [isRecording, setIsRecording] = useState(false)
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [isProcessing, setIsProcessing] = useState(false)
  const [currentPreset, setCurrentPreset] = useState('default')
  const [conversationHistory, setConversationHistory] = useState([])
  const [debugInfo, setDebugInfo] = useState([])
  const [processSteps, setProcessSteps] = useState([])
  const [lastUserSpeechTime, setLastUserSpeechTime] = useState(0) // Son kullanÄ±cÄ± konuÅŸma zamanÄ±

  // WebRTC referanslarÄ±
  const peerConnectionRef = useRef(null)
  const localStreamRef = useRef(null)
  const remoteStreamRef = useRef(null)
  const dataChannelRef = useRef(null)
  const audioContextRef = useRef(null)
  const audioQueueRef = useRef([])
  const isPlayingRef = useRef(false)

  // Debug ve log yÃ¶netimi
  const addDebugInfo = useCallback((message, type = 'info') => {
    const timestamp = new Date().toLocaleTimeString()
    setDebugInfo(prev => [...prev, { message, type, timestamp }])
    console.log(`[${timestamp}] ${type.toUpperCase()}: ${message}`)
  }, [])

  // Ä°ÅŸlem adÄ±mlarÄ±nÄ± takip etme
  const addProcessStep = useCallback((step, status = 'pending') => {
    setProcessSteps(prev => [...prev, { step, status, timestamp: new Date().toLocaleTimeString() }])
  }, [])

  const updateProcessStep = useCallback((step, status) => {
    setProcessSteps(prev => prev.map(s => s.step === step ? { ...s, status } : s))
  }, [])

  // Basit baÄŸlantÄ± baÅŸlatma (WebRTC olmadan)
  const initializeConnection = useCallback(async () => {
    try {
      addDebugInfo('BaÄŸlantÄ± baÅŸlatÄ±lÄ±yor...', 'info')
      addProcessStep('BaÄŸlantÄ±: Sistem hazÄ±rlanÄ±yor', 'in_progress')

      // Mikrofon eriÅŸimini test et
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      })

      // Test iÃ§in hemen kapat
      stream.getTracks().forEach(track => track.stop())
      
      addDebugInfo('Mikrofon eriÅŸimi test edildi', 'success')
      updateProcessStep('BaÄŸlantÄ±: Sistem hazÄ±rlanÄ±yor', 'completed')
      setIsConnected(true)
      addDebugInfo('Sistem hazÄ±r', 'success')

    } catch (error) {
      addDebugInfo(`BaÄŸlantÄ± hatasÄ±: ${error.message}`, 'error')
      updateProcessStep('BaÄŸlantÄ±: Sistem hazÄ±rlanÄ±yor', 'error')
    }
  }, [addDebugInfo, addProcessStep, updateProcessStep])

  // Uzak komutlarÄ± iÅŸleme
  const handleRemoteCommand = useCallback((command) => {
    addDebugInfo(`Uzak komut alÄ±ndÄ±: ${command.type}`, 'info')
    
    switch (command.type) {
      case 'start_speaking':
        setIsSpeaking(true)
        break
      case 'stop_speaking':
        setIsSpeaking(false)
        break
      case 'change_preset':
        setCurrentPreset(command.preset)
        break
      case 'system_message':
        addDebugInfo(`Sistem mesajÄ±: ${command.message}`, 'info')
        break
      default:
        addDebugInfo(`Bilinmeyen komut: ${command.type}`, 'warning')
    }
  }, [addDebugInfo])

  // Realtime ses iÅŸleme
  const processRealtimeAudio = useCallback(async (audioBlob) => {
    try {
      addProcessStep('STT: Realtime ses iÅŸleniyor', 'in_progress')
      addDebugInfo(`Realtime ses iÅŸleme baÅŸlatÄ±lÄ±yor: ${audioBlob.size} bytes`, 'info')

      // OpenAI Whisper ile iÅŸleme
      const formData = new FormData()
      formData.append('audio', audioBlob, 'realtime-audio.webm')

      const response = await fetch('/api/stt/stream', {
        method: 'POST',
        body: formData
      })

      if (response.ok) {
        const result = await response.json()
        addDebugInfo(`STT sonucu: "${result.text}"`, 'success')
        
        if (result.text && result.text.trim()) {
          const currentTime = Date.now()
          const timeSinceLastUserSpeech = currentTime - lastUserSpeechTime
          
          // EÄŸer AI konuÅŸuyorsa ve son kullanÄ±cÄ± konuÅŸmasÄ±ndan 5 saniye geÃ§memiÅŸse, bu muhtemelen AI'nin kendi sesi
          if (isSpeaking && timeSinceLastUserSpeech < 5000) {
            addDebugInfo('AI konuÅŸurken gelen ses, muhtemelen AI\'nin kendi sesi - yok sayÄ±lÄ±yor', 'warning')
            updateProcessStep('STT: Realtime ses iÅŸleniyor', 'cancelled');
            return
          }
          
          // KonuÅŸma geÃ§miÅŸine ekleme
          setConversationHistory(prev => [...prev, {
            type: 'user',
            text: result.text,
            timestamp: new Date().toISOString()
          }])
          
          setLastUserSpeechTime(currentTime)

          // GPT ile iÅŸleme
          await processRealtimeChat(result.text)
        }
      } else {
        const errorText = await response.text()
        addDebugInfo(`STT hatasÄ±: ${errorText}`, 'error')
      }

      updateProcessStep('STT: Realtime ses iÅŸleniyor', 'completed')

    } catch (error) {
      addDebugInfo(`Realtime ses iÅŸleme hatasÄ±: ${error.message}`, 'error')
      updateProcessStep('STT: Realtime ses iÅŸleniyor', 'error')
    }
  }, [addDebugInfo, addProcessStep, updateProcessStep])


  // Realtime chat iÅŸleme
  const processRealtimeChat = useCallback(async (userMessage) => {
    try {
      // Input validation - sadece gerÃ§ek kullanÄ±cÄ± input'u kabul et
      if (!userMessage.trim()) {
        addDebugInfo('BoÅŸ input, yanÄ±t verilmiyor', 'warning');
        return;
      }

      const trimmedMessage = userMessage.trim();
      if (trimmedMessage.length < 2) {
        addDebugInfo('Ã‡ok kÄ±sa input, yanÄ±t verilmiyor', 'warning');
        return;
      }

      // AI'nin kendi yanÄ±tlarÄ±nÄ± tekrar iÅŸlemesini engelle
      const aiResponsePatterns = [
        'Merhaba, ben Selin',
        'Size nasÄ±l yardÄ±mcÄ± olabilirim',
        'NasÄ±lsÄ±nÄ±z',
        'SaÃ§ Ekimi Merkezi',
        'FUE tekniÄŸi',
        'FUT tekniÄŸi',
        'DHI tekniÄŸi',
        'Sapphire FUE',
        'folikÃ¼ler Ã¼nite',
        'saÃ§ ekimi konusunda',
        'deneyimliyiz',
        'baÅŸarÄ± hikayesi',
        'kliniÄŸe yÃ¶nlendir',
        'randevu almak',
        'endÃ¼ÅŸelenmeyin',
        'gÃ¼ven verici'
      ];
      
      const isAiResponse = aiResponsePatterns.some(pattern => 
        trimmedMessage.toLowerCase().includes(pattern.toLowerCase())
      );
      
      if (isAiResponse) {
        addDebugInfo('AI kendi yanÄ±tÄ±nÄ± tekrar iÅŸlemeye Ã§alÄ±ÅŸÄ±yor, engellendi', 'warning');
        return;
      }

      addProcessStep('Chat: Realtime AI yanÄ±tÄ±', 'in_progress')
      addDebugInfo(`Realtime chat baÅŸlatÄ±lÄ±yor: "${trimmedMessage}"`, 'info')

      // ElevenLabs default preset'i al
      const preset = voicePresets.presets['default']
      
      // GPT config'i preset ile birleÅŸtir
      const systemPrompt = `${gptConfig.system_prompt}\n\n${preset.style_instructions}\n\n${gptConfig.voice_guidelines.sentence_structure}`

      const response = await fetch('/api/chat/stream', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          prompt: trimmedMessage,
          system_prompt: systemPrompt,
          max_tokens: gptConfig.technical_instructions.max_tokens,
          temperature: gptConfig.technical_instructions.temperature
        })
      })

      if (response.ok) {
        const reader = response.body.getReader()
        const decoder = new TextDecoder()
        let buffer = ''
        let fullResponse = ''

        while (true) {
          const { done, value } = await reader.read()
          if (done) break

          buffer += decoder.decode(value, { stream: true })
          const lines = buffer.split('\n')
          buffer = lines.pop() || ''

          for (const line of lines) {
            if (!line.startsWith('data: ')) continue
            const payload = line.slice(6).trim()
            if (!payload || payload === '[DONE]') continue

            try {
              const data = JSON.parse(payload)
              const chunk = data.text || ''
              if (chunk) {
                fullResponse += chunk
              }
            } catch (e) {
              // JSON parse hatasÄ±, devam et
            }
          }
        }

        if (fullResponse.trim()) {
          addDebugInfo(`AI yanÄ±tÄ±: "${fullResponse.trim()}"`, 'success')
          
          // KonuÅŸma geÃ§miÅŸine ekleme
          setConversationHistory(prev => [...prev, {
            type: 'assistant',
            text: fullResponse.trim(),
            timestamp: new Date().toISOString()
          }])

          // TTS ile seslendirme
          await processRealtimeTTS(fullResponse.trim(), preset)
        }
      }

      updateProcessStep('Chat: Realtime AI yanÄ±tÄ±', 'completed')

    } catch (error) {
      addDebugInfo(`Realtime chat hatasÄ±: ${error.message}`, 'error')
      updateProcessStep('Chat: Realtime AI yanÄ±tÄ±', 'error')
    }
  }, [currentPreset, addDebugInfo, addProcessStep, updateProcessStep])

  // Realtime TTS iÅŸleme
  const processRealtimeTTS = useCallback(async (text, preset) => {
    try {
      addProcessStep('TTS: Realtime ses Ã¼retimi', 'in_progress')
      addDebugInfo(`Realtime ElevenLabs TTS baÅŸlatÄ±lÄ±yor: "${text}"`, 'info')

      const response = await fetch('/api/tts/stream', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          text: text,
          voice_settings: preset.voice_settings
        })
      })

      if (response.ok) {
        const audioBuffer = await response.arrayBuffer()
        const audioBlob = new Blob([audioBuffer], { type: 'audio/mpeg' })
        
        // Ses kuyruÄŸuna ekleme
        audioQueueRef.current.push(audioBlob)
        
        // EÄŸer Ã§almÄ±yorsa baÅŸlat
        if (!isPlayingRef.current) {
          playNextAudio()
        }

        addDebugInfo(`TTS baÅŸarÄ±lÄ±: ${audioBlob.size} bytes`, 'success')
      }

      updateProcessStep('TTS: Realtime ses Ã¼retimi', 'completed')

    } catch (error) {
      addDebugInfo(`Realtime TTS hatasÄ±: ${error.message}`, 'error')
      updateProcessStep('TTS: Realtime TTS hatasÄ±', 'error')
    }
  }, [addDebugInfo, addProcessStep, updateProcessStep])

  // Ses Ã§alma kuyruÄŸu
  const playNextAudio = useCallback(() => {
    if (audioQueueRef.current.length > 0 && !isPlayingRef.current) {
      isPlayingRef.current = true
      setIsSpeaking(true)
      
      // AI konuÅŸurken mikrofonu tamamen durdur ve kayÄ±t yapmayÄ± engelle
      if (isRecording) {
        // KayÄ±t durdur
        if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
          mediaRecorderRef.current.stop()
          mediaRecorderRef.current = null
        }
        
        if (localStreamRef.current) {
          localStreamRef.current.getTracks().forEach(track => track.stop())
          localStreamRef.current = null
        }
        
        setIsRecording(false)
        addDebugInfo('AI konuÅŸuyor, mikrofon durduruldu', 'info')
      }

      const audioBlob = audioQueueRef.current.shift()
      const audioUrl = URL.createObjectURL(audioBlob)
      const audio = new Audio(audioUrl)

      audio.onended = () => {
        URL.revokeObjectURL(audioUrl)
        isPlayingRef.current = false
        setIsSpeaking(false)
        // Hemen bir sonraki sesi Ã§al (kesintisiz geÃ§iÅŸ)
        setTimeout(() => {
          playNextAudio()
        }, 50)
      }

      audio.onerror = () => {
        URL.revokeObjectURL(audioUrl)
        isPlayingRef.current = false
        setIsSpeaking(false)
        playNextAudio()
      }

      audio.play().catch(console.error)
    }
  }, [isRecording, addDebugInfo])

  // KayÄ±t baÅŸlatma/durdurma
  const toggleRecording = useCallback(async () => {
    if (isRecording) {
      // KayÄ±t durdur
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
        mediaRecorderRef.current.stop()
        mediaRecorderRef.current = null
      }
      
      if (localStreamRef.current) {
        localStreamRef.current.getTracks().forEach(track => track.stop())
        localStreamRef.current = null
      }
      
      setIsRecording(false)
      addDebugInfo('KayÄ±t durduruldu', 'info')
    } else {
      // AI konuÅŸuyorsa kayÄ±t yapma
      if (isSpeaking) {
        addDebugInfo('AI konuÅŸuyor, kayÄ±t yapÄ±lamÄ±yor', 'warning')
        return
      }
      
      // KayÄ±t baÅŸlat
      try {
        addDebugInfo('KayÄ±t baÅŸlatÄ±lÄ±yor...', 'info')
        addProcessStep('KayÄ±t: Mikrofon eriÅŸimi', 'in_progress')
        
        // Mikrofon eriÅŸimi
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            sampleRate: 16000,
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          }
        })

        localStreamRef.current = stream
        addDebugInfo('Mikrofon eriÅŸimi baÅŸarÄ±lÄ±', 'success')
        updateProcessStep('KayÄ±t: Mikrofon eriÅŸimi', 'completed')

        // MediaRecorder oluÅŸtur - WebM formatÄ± kullan (OpenAI destekliyor)
        const mediaRecorder = new MediaRecorder(stream, {
          mimeType: 'audio/webm'
        })
        
        addDebugInfo(`MediaRecorder formatÄ±: audio/webm`, 'info')

        mediaRecorderRef.current = mediaRecorder
        setIsRecording(true)
        addDebugInfo('KayÄ±t baÅŸlatÄ±ldÄ±', 'success')

        // Ses verisi geldiÄŸinde iÅŸle
        mediaRecorder.ondataavailable = async (event) => {
          if (event.data.size > 0) {
            addDebugInfo(`Ses verisi alÄ±ndÄ±: ${event.data.size} bytes`, 'info')
            addProcessStep('STT: Ses iÅŸleniyor', 'in_progress')
            await processRealtimeAudio(event.data)
          }
        }

        // KayÄ±t hatalarÄ±nÄ± yakala
        mediaRecorder.onerror = (event) => {
          addDebugInfo(`KayÄ±t hatasÄ±: ${event.error}`, 'error')
          setIsRecording(false)
        }

        // KayÄ±t baÅŸlat (1 saniyede bir chunk)
        mediaRecorder.start(1000)

      } catch (error) {
        addDebugInfo(`KayÄ±t baÅŸlatma hatasÄ±: ${error.message}`, 'error')
        updateProcessStep('KayÄ±t: Mikrofon eriÅŸimi', 'error')
        console.error('Recording error:', error)
      }
    }
  }, [isRecording, isSpeaking, addDebugInfo, addProcessStep, updateProcessStep])

  // ArtÄ±k sadece default preset kullanÄ±yoruz - changePreset fonksiyonu kaldÄ±rÄ±ldÄ±

  // BaÄŸlantÄ±yÄ± kapatma
  const disconnect = useCallback(() => {
    if (localStreamRef.current) {
      localStreamRef.current.getTracks().forEach(track => track.stop())
      localStreamRef.current = null
    }

    if (mediaRecorderRef.current) {
      mediaRecorderRef.current.stop()
      mediaRecorderRef.current = null
    }

    setIsConnected(false)
    setIsRecording(false)
    setIsSpeaking(false)
    addDebugInfo('BaÄŸlantÄ± kapatÄ±ldÄ±', 'info')
  }, [addDebugInfo])

  // Component mount olduÄŸunda baÄŸlantÄ±yÄ± baÅŸlat ve geÃ§miÅŸi temizle
  useEffect(() => {
    // Sayfa yenilendiÄŸinde tÃ¼m geÃ§miÅŸi temizle
    setConversationHistory([])
    setDebugInfo([])
    setProcessSteps([])
    addDebugInfo('Sayfa yenilendi, tÃ¼m geÃ§miÅŸ temizlendi', 'info')
    
    initializeConnection()
    
    return () => {
      disconnect()
    }
  }, [initializeConnection, disconnect, addDebugInfo])

  return (
    <div className="bg-white rounded-2xl shadow-xl p-6 border border-gray-100">
      {/* BaÅŸlÄ±k */}
      <div className="text-center mb-6">
        <h2 className="text-2xl font-bold text-gray-900 mb-2">Realtime AI Asistan</h2>
        <p className="text-gray-600">WebRTC ile gerÃ§ek zamanlÄ± sesli konuÅŸma</p>
        <div className="mt-2 flex justify-center space-x-2 text-xs text-gray-500">
          <span className="bg-blue-100 text-blue-800 px-2 py-1 rounded">WebRTC</span>
          <span className="bg-green-100 text-green-800 px-2 py-1 rounded">Realtime STT</span>
          <span className="bg-purple-100 text-purple-800 px-2 py-1 rounded">Smart TTS</span>
        </div>
      </div>

      {/* BaÄŸlantÄ± Durumu */}
      <div className="text-center mb-4">
        <div className={`inline-flex items-center px-3 py-1 rounded-full text-sm font-medium ${
          isConnected ? 'bg-green-100 text-green-800' : 'bg-red-100 text-red-800'
        }`}>
          <div className={`w-2 h-2 rounded-full mr-2 ${
            isConnected ? 'bg-green-500' : 'bg-red-500'
          }`}></div>
          {isConnected ? 'BaÄŸlÄ±' : 'BaÄŸlantÄ± Yok'}
        </div>
      </div>

      {/* ElevenLabs Voice Info */}
      <div className="mb-6">
        <h3 className="text-sm font-semibold text-gray-700 mb-3">ElevenLabs Ses Sistemi</h3>
        <div className="bg-gradient-to-r from-purple-50 to-blue-50 rounded-lg p-4 border border-purple-200">
          <div className="text-center">
            <div className="text-2xl mb-2">ğŸ™ï¸</div>
            <div className="font-medium text-gray-800">{voicePresets.presets.default.name}</div>
            <div className="text-sm text-gray-600 mt-1">{voicePresets.presets.default.description}</div>
            <div className="text-xs text-gray-500 mt-2">
              Voice ID: <span className="font-mono bg-gray-100 px-2 py-1 rounded">{voicePresets.elevenlabs_config.voice_id}</span>
            </div>
          </div>
        </div>
      </div>

      {/* Kontrol ButonlarÄ± */}
      <div className="text-center mb-6">
        <button
          onClick={toggleRecording}
          disabled={!isConnected || isProcessing || isSpeaking}
          className={`w-24 h-24 rounded-full text-white font-bold text-lg transition-all duration-200 transform hover:scale-105 disabled:opacity-50 disabled:cursor-not-allowed ${
            isRecording 
              ? 'bg-red-500 hover:bg-red-600 shadow-lg' 
              : isSpeaking
              ? 'bg-yellow-500 shadow-lg'
              : 'bg-gradient-to-r from-indigo-500 to-purple-500 hover:from-indigo-600 hover:to-purple-600 shadow-lg'
          }`}
        >
          {isRecording ? 'â– ' : isSpeaking ? 'ğŸ”Š' : 'â—'}
        </button>
        <p className="mt-2 text-sm text-gray-600">
          {isRecording ? 'KayÄ±t yapÄ±lÄ±yor...' : 'KayÄ±t baÅŸlat'}
        </p>
      </div>

      {/* Durum GÃ¶stergeleri */}
      <div className="grid grid-cols-3 gap-4 mb-6">
        <div className="text-center p-3 bg-gray-50 rounded-lg">
          <div className={`w-4 h-4 rounded-full mx-auto mb-2 ${
            isRecording ? 'bg-red-500 animate-pulse' : 'bg-gray-300'
          }`}></div>
          <div className="text-xs text-gray-600">KayÄ±t</div>
        </div>
        <div className="text-center p-3 bg-gray-50 rounded-lg">
          <div className={`w-4 h-4 rounded-full mx-auto mb-2 ${
            isProcessing ? 'bg-yellow-500 animate-pulse' : 'bg-gray-300'
          }`}></div>
          <div className="text-xs text-gray-600">Ä°ÅŸleme</div>
        </div>
        <div className="text-center p-3 bg-gray-50 rounded-lg">
          <div className={`w-4 h-4 rounded-full mx-auto mb-2 ${
            isSpeaking ? 'bg-green-500 animate-pulse' : 'bg-gray-300'
          }`}></div>
          <div className="text-xs text-gray-600">KonuÅŸma</div>
        </div>
      </div>

      {/* KonuÅŸma GeÃ§miÅŸi */}
      <div className="mb-6">
        <h3 className="text-sm font-semibold text-gray-700 mb-3">KonuÅŸma GeÃ§miÅŸi</h3>
        <div className="bg-gray-50 rounded-lg p-4 max-h-40 overflow-y-auto">
          {conversationHistory.length === 0 ? (
            <div className="text-gray-500 text-sm">HenÃ¼z konuÅŸma yok...</div>
          ) : (
            conversationHistory.map((message, index) => (
              <div key={index} className={`mb-2 p-2 rounded ${
                message.type === 'user' 
                  ? 'bg-blue-100 text-blue-800 ml-4' 
                  : 'bg-green-100 text-green-800 mr-4'
              }`}>
                <div className="text-xs text-gray-500 mb-1">
                  {message.type === 'user' ? 'Sen' : 'AI'} - {new Date(message.timestamp).toLocaleTimeString()}
                </div>
                <div className="text-sm">{message.text}</div>
              </div>
            ))
          )}
        </div>
      </div>

      {/* Ä°ÅŸlem AdÄ±mlarÄ± */}
      {processSteps.length > 0 && (
        <div className="mb-6">
          <h3 className="text-sm font-semibold text-gray-700 mb-3">Ä°ÅŸlem AdÄ±mlarÄ±</h3>
          <div className="space-y-2">
            {processSteps.map((step, index) => (
              <div key={index} className="flex items-center p-2 bg-gray-50 rounded-lg">
                <div className={`w-4 h-4 rounded-full flex items-center justify-center mr-3 ${
                  step.status === 'completed' ? 'bg-green-500' :
                  step.status === 'in_progress' ? 'bg-blue-500 animate-pulse' :
                  step.status === 'error' ? 'bg-red-500' :
                  'bg-gray-400'
                }`}>
                  {step.status === 'completed' ? (
                    <svg className="w-3 h-3 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                      <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 13l4 4L19 7" />
                    </svg>
                  ) : step.status === 'in_progress' ? (
                    <div className="w-2 h-2 bg-white rounded-full animate-pulse"></div>
                  ) : step.status === 'error' ? (
                    <svg className="w-3 h-3 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                      <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
                    </svg>
                  ) : (
                    <div className="w-1 h-1 bg-white rounded-full"></div>
                  )}
                </div>
                <div className="flex-1">
                  <div className="text-xs font-medium text-gray-900">{step.step}</div>
                  <div className="text-xs text-gray-500">{step.timestamp}</div>
                </div>
              </div>
            ))}
          </div>
        </div>
      )}

      {/* Debug Bilgileri */}
      <div className="mb-6">
        <div className="flex justify-between items-center mb-2">
          <h3 className="text-sm font-semibold text-gray-700">Debug Bilgileri</h3>
          <button
            onClick={() => setDebugInfo([])}
            className="text-xs text-gray-500 hover:text-gray-700 px-2 py-1 rounded hover:bg-gray-100"
          >
            Temizle
          </button>
        </div>
        <div className="bg-gray-900 text-green-400 p-3 rounded-lg text-xs font-mono max-h-32 overflow-y-auto">
          {debugInfo.length === 0 ? (
            <div className="text-gray-500">Debug bilgileri burada gÃ¶rÃ¼necek...</div>
          ) : (
            debugInfo.map((info, index) => (
              <div key={index} className={`mb-1 ${
                info.type === 'error' ? 'text-red-400' :
                info.type === 'success' ? 'text-green-400' :
                info.type === 'warning' ? 'text-yellow-400' :
                'text-blue-400'
              }`}>
                <span className="text-gray-500">[{info.timestamp}]</span> {info.message}
              </div>
            ))
          )}
        </div>
      </div>

      {/* BaÄŸlantÄ± KontrolÃ¼ */}
      <div className="text-center">
        <button
          onClick={isConnected ? disconnect : initializeConnection}
          className={`px-4 py-2 rounded-lg text-sm font-medium transition-colors ${
            isConnected 
              ? 'bg-red-100 text-red-800 hover:bg-red-200' 
              : 'bg-green-100 text-green-800 hover:bg-green-200'
          }`}
        >
          {isConnected ? 'BaÄŸlantÄ±yÄ± Kes' : 'BaÄŸlan'}
        </button>
      </div>
    </div>
  )
}
